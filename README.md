# asentmax

Code for [Long-Context Generalization with Sparse Attention](https://arxiv.org/abs/2506.16640).

## Requirements

Install [AdaSplash](https://github.com/deep-spin/adasplash) for the entmax attention kernel.

WIP
